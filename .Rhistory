#                                                     cm_email,
#                                                     bdh_email,
#                                                     bdm_email
#                                               from okr_raw
#                                             where country_id in (211)"))
#
# okr = merge(hotels_data, okr_ops, by.x = c("oyo_id"), by.y = c("oyo_id"), all.x = TRUE)
#
# okr_N_R = okr[,c(1,2,3,8,9)]
# okr_A_E = okr[,c(1,4,5,6,7)]
#
# write.csv(okr_A_E, "Property_Data_A_E.csv", row.names = FALSE)
# write.csv(okr_N_R, "Property_Data_N_R.csv", row.names = FALSE)
hotels_data = dbGetQuery(con, statement = paste0("
select h.oyo_id, h.hotel_id, h.hotel_name,  h.status_name, h.oyo_product, h2.total_contracted_rooms, h.cluster_name,
h.city_name, h.hub_name, element_at(h.okr_details,'Remote Ops Associate Level 2') as ppm_email, element_at(h.okr_details,'BD Manager') as bd_email,
element_at(h.okr_details,'Cluster Manager') as cm_email,
element_at(h.okr_details,'Ops Head') as oh_email
from aggregatedb.hotels_summary h
left join (select * from aggregatedb.hotel_date_summary where country_id in (211,43) and date(d)=current_date) h2 on h2.oyo_id=h.oyo_id
where h.country_id in (211,43)
and h.hotel_name not LIKE '%test%'
and h.hotel_name not LIKE '%Test%'
and h.hotel_name not LIKE '%training%'
and h.hotel_name not LIKE '%Training%'
and h.hotel_name not LIKE '%sachin%'
and h.hotel_name not LIKE '%remote%'
"))
first_live_date = dbGetQuery(con, statement = paste0("select oyo_id, cast(time as date) as live_date from (select hsc.*, row_number() over (partition by hsc.oyo_id order by  hsc.time) as RN
from aggregatedb.property_status_changes hsc
left join aggregatedb.hotels_summary hs on hs.oyo_id = hsc.oyo_id
where hs.country_id in (211,43)
and new_status='Live')
where RN=1"))
hotels_data = merge(hotels_data, first_live_date, by.x = c("oyo_id"), by.y = c("oyo_id"), all.x = TRUE)
write.csv(hotels_data, "Property_Data.csv", row.names = FALSE)
#Image Score
##################################################################
#Social Media from Social Media Tracker
# Social_raw <- gs_key("1q8Jr6GW-0KCCtRnsaK5k0s8N4Jopn1RT1wqUxt-s9dk")
# Social <- gs_read(ss=Social_raw, ws = "Nov19")  #, skip = 1)
# Social <- dplyr::filter(Social, Social$Country == "USA", Social$Date >= "01/10")
# write.csv(Social, "Social.csv", row.names = FALSE)
Sys.setenv(RETICULATE_PYTHON = "C:/Users/oyo/Anaconda3/python.exe")
library(reticulate)
repl_python()
import pandas as pd
from httplib2 import http
from httplib2 import Http
from googleapiclient  import discovery
#from apiclient  import discovery
from oauth2client import client
from oauth2client import tools
from oauth2client.file import Storage
from oauth2client import file,client,tools
import psycopg2
from df2gspread import df2gspread as d2g
import pandas as pd
import numpy as np
import logging
import time
logging.getLogger('googleapicliet.discovery_cache').setLevel(logging.ERROR)
#df=okr1
#####set na values to null
CLIENT_SECRET = 'D:/client_secret.json'
SCOPE='https://www.googleapis.com/auth/spreadsheets'
store = file.Storage('D:/Storage.json')
credz= store.get()
if not credz :
flow = client.flow_from_clientsecrets(CLIENT_SECRET,SCOPE);credz = tools.run_flow(flow,store)
# df1=pd.read_csv("blocked_rooms.csv",encoding='latin-1')
# df1 = df1.replace(np.nan, '', regex=True)
# heads = df1.columns.values.tolist()
# dataa1 = [heads] + df1.values.tolist()
# data11 = { 'values' : [row[:50] for row in dataa1]}
# SHEETS = discovery.build('sheets','v4',http=credz.authorize(Http()),cache_discovery=False)
# request = SHEETS.spreadsheets().values().clear(spreadsheetId='1DbrVcKM-d4RddnzW1uXY7MbEjhLeRS3BVyoLf42HaPE', range='Blocked Rooms!A:I', body={})
# response = request.execute()
# SHEETS.spreadsheets().values().update(spreadsheetId='1DbrVcKM-d4RddnzW1uXY7MbEjhLeRS3BVyoLf42HaPE', range='Blocked Rooms!A:I',body= data11,valueInputOption= 'USER_ENTERED').execute()
# print ("Uploading Done")
#
#
# # df1=pd.read_csv("Blocked_Rooms_K_U.csv",encoding='latin-1')
# # df1 = df1.replace(np.nan, '', regex=True)
# # heads = df1.columns.values.tolist()
# # dataa1 = [heads] + df1.values.tolist()
# # data11 = { 'values' : [row[:50] for row in dataa1]}
# # SHEETS = discovery.build('sheets','v4',http=credz.authorize(Http()),cache_discovery=False)
# # request = SHEETS.spreadsheets().values().clear(spreadsheetId='1DbrVcKM-d4RddnzW1uXY7MbEjhLeRS3BVyoLf42HaPE', range='Blocked Rooms!K:U', body={})
# # response = request.execute()
# # SHEETS.spreadsheets().values().update(spreadsheetId='1DbrVcKM-d4RddnzW1uXY7MbEjhLeRS3BVyoLf42HaPE', range='Blocked Rooms!K:U',body= data11,valueInputOption= 'USER_ENTERED').execute()
# # print ("Uploading Done")
#
#
# df1=pd.read_csv("property_data_G_L.csv",encoding='latin-1')
# df1 = df1.replace(np.nan, '', regex=True)
# heads = df1.columns.values.tolist()
# dataa1 = [heads] + df1.values.tolist()
# data11 = { 'values' : [row[:50] for row in dataa1]}
#
#
#
# df1=pd.read_csv("Property_Data_N_R.csv",encoding='latin-1')
# df1 = df1.replace(np.nan, '', regex=True)
# heads = df1.columns.values.tolist()
# dataa1 = [heads] + df1.values.tolist()
# data11 = { 'values' : [row[:50] for row in dataa1]}
# df1=pd.read_csv("Social.csv",encoding='latin-1')
# df1 = df1.replace(np.nan, '', regex=True)
# heads = df1.columns.values.tolist()
# dataa1 = [heads] + df1.values.tolist()
# data11 = { 'values' : [row[:50] for row in dataa1]}
# SHEETS = discovery.build('sheets','v4',http=credz.authorize(Http()),cache_discovery=False)
# request = SHEETS.spreadsheets().values().clear(spreadsheetId='1DbrVcKM-d4RddnzW1uXY7MbEjhLeRS3BVyoLf42HaPE', range='Social Media Escalations', body={})
# response = request.execute()
# SHEETS.spreadsheets().values().update(spreadsheetId='1DbrVcKM-d4RddnzW1uXY7MbEjhLeRS3BVyoLf42HaPE', range='Social Media Escalations',body= data11,valueInputOption= 'USER_ENTERED').execute()
# print ("Uploading Done")
df1=pd.read_csv("Property_Data.csv",encoding='latin-1')
df1 = df1.replace(np.nan, '', regex=True)
heads = df1.columns.values.tolist()
dataa1 = [heads] + df1.values.tolist()
data11 = { 'values' : [row[:50] for row in dataa1]}
SHEETS = discovery.build('sheets','v4',http=credz.authorize(Http()),cache_discovery=False)
request = SHEETS.spreadsheets().values().clear(spreadsheetId='1DbrVcKM-d4RddnzW1uXY7MbEjhLeRS3BVyoLf42HaPE', range='Property Data!A:N', body={})
response = request.execute()
SHEETS.spreadsheets().values().update(spreadsheetId='1DbrVcKM-d4RddnzW1uXY7MbEjhLeRS3BVyoLf42HaPE', range='Property Data!A:N',body= data11,valueInputOption= 'USER_ENTERED').execute()
print ("Uploading Done")
exit
rm(list=ls())
library(xlsx)
library(mailR)
#library (syuzhet)
library(plyr)
library(dplyr)
library(tidyr)
library(lazyeval)
library(DBI)
library(RPostgreSQL)
library(xtable)
library(reshape2)
library(rJava)
library(formattable)
library(condformat)
library(htmlTable)
library(RSQLite)
library(googlesheets)
library(mongolite)
library(lubridate)
library('data.table')
time <- as.POSIXlt(Sys.time(), "Asia/Calcutta")
hour = as.integer(format(as.POSIXct(time,format="%H:%M:%S"),"%H"))
start_date="2021-04-22"
end_date="2021-06-24"
print(start_date)
print(end_date)
mweb_usa = desktopweb_usa = and_usa = ios_usa = data.frame()
for(i in 1:2){
mweb_usa <-   as.data.frame(get_ga(profileId = 'ga:206313409',
start.date = start_date,
end.date = end_date,
metrics = c('ga:sessions','ga:users'),
dimensions = c('ga:date','ga:hour'),
sort = NULL,
filters = NULL,
segment = NULL,
samplingLevel ='HIGHER_PRECISION',
start.index = NULL,
max.results = NULL,
include.empty.rows = NULL,
fetch.by = 'day',ga_token))
mweb_usa$date <- as.character(mweb_usa$date)
mweb_usa$source=21
if(nrow(mweb_usa) > 0 ) break;
}
source('C:/Users/khare/Documents/R/win-library/4.1/httr/demo/connection-sharing.r')
source('C:/Users/khare/Documents/R/win-library/4.1/httr/demo/connection-sharing.R')
install.packages("connections")
library(connections)
source('C:/Users/khare/Documents/R/win-library/4.1/connections/R')
source('C:/Users/khare/Documents/R/win-library/4.1/connections')
source('C:/Users/khare/Documents/R/win-library/4.1/connections',"r", encoding = encoding)
source('C:/Users/khare/Documents/R/win-library/4.1/connections', encoding = encoding)
source('C:/Users/khare/Documents/R/win-library/4.1/connections')
rm(list = ls())
library(recommenderlab)
library(ggplot2)                       #Author DataFlair
library(data.table)
library(reshape2)
setwd("C:/Users/khare/code/Self Project/Movie Recommendation System")                       #Author DataFlair
movie_data <- read.csv("C:/Users/khare/code/Self Project/Movie Recommendation System/Raw Data/movies.csv",stringsAsFactors=FALSE)
rating_data <- read.csv("C:/Users/khare/code/Self Project/Movie Recommendation System/Raw Data/ratings.csv")
str(movie_data)
movie_data
summary(movie_data)    #Author DataFlair
head(movie_data)
head(rating_data)
summary(rating_data)
movie_genre <- as.data.frame(movie_data$genres, stringsAsFactors=FALSE)
library(data.table)
movie_genre2 <- as.data.frame(tstrsplit(movie_genre[,1], '[|]',
type.convert=TRUE),
stringsAsFactors=FALSE) #DataFlair
colnames(movie_genre2) <- c(1:10)
list_genre <- c("Action", "Adventure", "Animation", "Children",
"Comedy", "Crime","Documentary", "Drama", "Fantasy",
"Film-Noir", "Horror", "Musical", "Mystery","Romance",
"Sci-Fi", "Thriller", "War", "Western")
genre_mat1 <- matrix(0,10330,18)
genre_mat1[1,] <- list_genre
colnames(genre_mat1) <- list_genre
for (index in 1:nrow(movie_genre2)) {
for (col in 1:ncol(movie_genre2)) {
gen_col = which(genre_mat1[1,] == movie_genre2[index,col]) #Author DataFlair
genre_mat1[index+1,gen_col] <- 1
}
}
genre_mat2 <- as.data.frame(genre_mat1[-1,], stringsAsFactors=FALSE) #remove first row, which was the genre list
for (col in 1:ncol(genre_mat2)) {
genre_mat2[,col] <- as.integer(genre_mat2[,col]) #convert from characters to integers
}
str(genre_mat2)
SearchMatrix <- cbind(movie_data[,1:2], genre_mat2[])
head(SearchMatrix)    #DataFlair
ratingMatrix <- dcast(rating_data, userId~movieId, value.var = "rating", na.rm=FALSE)
ratingMatrix <- as.matrix(ratingMatrix[,-1]) #remove userIds
movie_genre2 <- as.data.frame(tstrsplit(movie_genre[,1], '[|]',
type.convert=TRUE),
stringsAsFactors=FALSE) #DataFlair
rm(list = ls())
library(recommenderlab)
library(ggplot2)                       #Author DataFlair
library(data.table)
library(reshape2)
setwd("C:/Users/khare/code/Self Project/Movie Recommendation System")                       #Author DataFlair
movie_data <- read.csv("C:/Users/khare/code/Self Project/Movie Recommendation System/Raw Data/movies.csv",stringsAsFactors=FALSE)
rating_data <- read.csv("C:/Users/khare/code/Self Project/Movie Recommendation System/Raw Data/ratings.csv")
str(movie_data)
movie_data
summary(movie_data)    #Author DataFlair
head(movie_data)
summary(rating_data)
head(rating_data)
movie_genre <- as.data.frame(movie_data$genres, stringsAsFactors=FALSE)
library(data.table)
movie_genre2 <- as.data.frame(tstrsplit(movie_genre[,1], '[|]',
type.convert=TRUE),
stringsAsFactors=FALSE) #DataFlair
colnames(movie_genre2) <- c(1:10)
list_genre <- c("Action", "Adventure", "Animation", "Children",
"Comedy", "Crime","Documentary", "Drama", "Fantasy",
"Film-Noir", "Horror", "Musical", "Mystery","Romance",
"Sci-Fi", "Thriller", "War", "Western")
genre_mat1 <- matrix(0,10330,18)
genre_mat1[1,] <- list_genre
colnames(genre_mat1) <- list_genre
for (index in 1:nrow(movie_genre2)) {
for (col in 1:ncol(movie_genre2)) {
gen_col = which(genre_mat1[1,] == movie_genre2[index,col]) #Author DataFlair
genre_mat1[index+1,gen_col] <- 1
}
}
genre_mat2 <- as.data.frame(genre_mat1[-1,], stringsAsFactors=FALSE) #remove first row, which was the genre list
for (col in 1:ncol(genre_mat2)) {
genre_mat2[,col] <- as.integer(genre_mat2[,col]) #convert from characters to integers
}
str(genre_mat2)
SearchMatrix <- cbind(movie_data[,1:2], genre_mat2[])
head(SearchMatrix)    #DataFlair
ratingMatrix <- dcast(rating_data, userId~movieId, value.var = "rating", na.rm=FALSE)
ratingMatrix <- as.matrix(ratingMatrix[,-1]) #remove userIds
#Convert rating matrix into a recommenderlab sparse matrix
ratingMatrix <- as(ratingMatrix, "realRatingMatrix")
ratingMatrix
recommendation_model <- recommenderRegistry$get_entries(dataType = "realRatingMatrix")
View(ratingMatrix)
View(ratingMatrix)
View(ratingMatrix)
View(SearchMatrix)
View(recommendation_model)
names(recommendation_model)
lapply(recommendation_model, "[[", "description")
recommendation_model$IBCF_realRatingMatrix$parameters
recommendation_model <- recommenderRegistry$get_entries(dataType = "realRatingMatrix")
names(recommendation_model)
lapply(recommendation_model, "[[", "description")
recommendation_model$IBCF_realRatingMatrix$parameters
similarity_mat <- similarity(ratingMatrix[1:4, ],
method = "cosine",
which = "users")
as.matrix(similarity_mat)
View(ratingMatrix)
write.xlxs(ratingMatrix,paste("static_",".xlxs",sep=""),row.names = FALSE)
library(writexl)
install.packages("writexl")
library(writexl)
write_xlsx(ratingMatrix,paste("static_",".xlxs",sep=""),row.names = FALSE)
install.packages("xlsx")
library("xlsx")
write.xlsx(ratingMatrix,paste("static_",".xlxs",sep=""),row.names = FALSE)
write.xlsx(ratingMatrix,paste("static_",".xlxs",sep=""))
View(SearchMatrix)
View(ratingMatrix)
similarity_mat <- similarity(ratingMatrix[1:4, ],
method = "cosine",
which = "users")
as.matrix(similarity_mat)
write.xlsx(ratingMatrix,paste("static_",".xlxs",sep=""))
image(as.matrix(similarity_mat), main = "User's Similarities")
movie_similarity <- similarity(ratingMatrix[, 1:4], method =
"cosine", which = "items")
as.matrix(movie_similarity)
image(as.matrix(movie_similarity), main = "Movies similarity")
rating_values <- as.vector(ratingMatrix@data)
unique(rating_values) # extracting unique ratings
Table_of_Ratings <- table(rating_values) # creating a count of movie ratings
Table_of_Ratings
ratingMatrix@data@Dimnames
library(ggplot2)
movie_views <- colCounts(ratingMatrix) # count views for each movie
movie_views
table_views <- data.frame(movie = names(movie_views),
views = movie_views) # create dataframe of views
table_views <- table_views[order(table_views$views,
decreasing = TRUE), ] # sort by number of views
table_views$title <- NA
View(table_views)
for (index in 1:10325){
table_views[index,3] <- as.character(subset(movie_data,
movie_data$movieId == table_views[index,1])$title)
}
table_views[1:6,]
View(table_views)
View(table_views)
View(table_views)
ggplot(table_views[1:6, ], aes(x = title, y = views)) +
geom_bar(stat="identity", fill = 'steelblue') +
geom_text(aes(label=views), vjust=-0.3, size=3.5) +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
ggtitle("Total Views of the Top Films")
image(ratingMatrix[1:20, 1:25], axes = FALSE, main = "Heatmap of the first 25 rows and 25 columns")
View(ratingMatrix)
ratingMatrix@data@p
movie_ratings <- ratingMatrix[rowCounts(ratingMatrix) > 50,
colCounts(ratingMatrix) > 50]
movie_ratings
View(movie_ratings)
minimum_movies<- quantile(rowCounts(movie_ratings), 0.98)
minimum_users <- quantile(colCounts(movie_ratings), 0.98)
image(movie_ratings[rowCounts(movie_ratings) > minimum_movies,
colCounts(movie_ratings) > minimum_users],
main = "Heatmap of the top users and movies")
average_ratings <- rowMeans(movie_ratings)
qplot(average_ratings, fill=I("steelblue"), col=I("red")) +
ggtitle("Distribution of the average rating per user")
normalized_ratings <- normalize(movie_ratings)
sum(rowMeans(normalized_ratings) > 0.00001)
image(normalized_ratings[rowCounts(normalized_ratings) > minimum_movies,
colCounts(normalized_ratings) > minimum_users],
main = "Normalized Ratings of the Top Users")
binary_minimum_movies <- quantile(rowCounts(movie_ratings), 0.95)
binary_minimum_users <- quantile(colCounts(movie_ratings), 0.95)
good_rated_films <- binarize(movie_ratings, minRating = 3)
image(good_rated_films[rowCounts(movie_ratings) > binary_minimum_movies,
colCounts(movie_ratings) > binary_minimum_users],
main = "Heatmap of the top users and movies")
sampled_data<- sample(x = c(TRUE, FALSE),
size = nrow(movie_ratings),
replace = TRUE,
prob = c(0.8, 0.2))
training_data <- movie_ratings[sampled_data, ]
testing_data <- movie_ratings[!sampled_data, ]
recommendation_system <- recommenderRegistry$get_entries(dataType ="realRatingMatrix")
recommendation_system$IBCF_realRatingMatrix$parameters
recommen_model <- Recommender(data = training_data,
method = "IBCF",
parameter = list(k = 30))
recommen_model
class(recommen_model)
model_info <- getModel(recommen_model)
class(model_info$sim)
dim(model_info$sim)
top_items <- 20
image(model_info$sim[1:top_items, 1:top_items],
main = "Heatmap of the first rows and columns")
sum_rows <- rowSums(model_info$sim > 0)
table(sum_rows)
sum_cols <- colSums(model_info$sim > 0)
qplot(sum_cols, fill=I("steelblue"), col=I("red"))+ ggtitle("Distribution of the column count")
top_recommendations <- 10 # the number of items to recommend to each user
predicted_recommendations <- predict(object = recommen_model,
newdata = testing_data,
n = top_recommendations)
predicted_recommendations
user1 <- predicted_recommendations@items[[1]] # recommendation for the first user
movies_user1 <- predicted_recommendations@itemLabels[user1]
movies_user2 <- movies_user1
for (index in 1:10){
movies_user2[index] <- as.character(subset(movie_data,
movie_data$movieId == movies_user1[index])$title)
}
movies_user2
recommendation_matrix <- sapply(predicted_recommendations@items,
function(x){ as.integer(colnames(movie_ratings)[x]) }) # matrix with the recommendations for each user
#dim(recc_matrix)
recommendation_matrix[,1:4]
View(recommendation_matrix)
View(ratingMatrix)
rm(list = ls())
library(recommenderlab)
library(ggplot2)                       #Author DataFlair
library(data.table)
library(writexl)
library(reshape2)
library("xlsx")
setwd("C:/Users/khare/code/Self Project/Movie Recommendation System")                       #Author DataFlair
movie_data <- read.csv("C:/Users/khare/code/Self Project/Movie Recommendation System/Raw Data/movies.csv",stringsAsFactors=FALSE)
rating_data <- read.csv("C:/Users/khare/code/Self Project/Movie Recommendation System/Raw Data/ratings.csv")
str(movie_data)
movie_data
summary(movie_data)    #Author DataFlair
summary(rating_data)
head(movie_data)
head(rating_data)
movie_genre <- as.data.frame(movie_data$genres, stringsAsFactors=FALSE)
library(data.table)
movie_genre2 <- as.data.frame(tstrsplit(movie_genre[,1], '[|]',
type.convert=TRUE),
stringsAsFactors=FALSE) #DataFlair
colnames(movie_genre2) <- c(1:10)
list_genre <- c("Action", "Adventure", "Animation", "Children",
"Comedy", "Crime","Documentary", "Drama", "Fantasy",
"Film-Noir", "Horror", "Musical", "Mystery","Romance",
"Sci-Fi", "Thriller", "War", "Western")
genre_mat1 <- matrix(0,10330,18)
genre_mat1[1,] <- list_genre
colnames(genre_mat1) <- list_genre
for (index in 1:nrow(movie_genre2)) {
for (col in 1:ncol(movie_genre2)) {
gen_col = which(genre_mat1[1,] == movie_genre2[index,col]) #Author DataFlair
genre_mat1[index+1,gen_col] <- 1
}
}
genre_mat2 <- as.data.frame(genre_mat1[-1,], stringsAsFactors=FALSE) #remove first row, which was the genre list
for (col in 1:ncol(genre_mat2)) {
genre_mat2[,col] <- as.integer(genre_mat2[,col]) #convert from characters to integers
}
str(genre_mat2)
SearchMatrix <- cbind(movie_data[,1:2], genre_mat2[])
head(SearchMatrix)    #DataFlair
ratingMatrix <- dcast(rating_data, userId~movieId, value.var = "rating", na.rm=FALSE)
ratingMatrix <- as.matrix(ratingMatrix[,-1]) #remove userIds
#Convert rating matrix into a recommenderlab sparse matrix
ratingMatrix <- as(ratingMatrix, "realRatingMatrix")
ratingMatrix
recommendation_model <- recommenderRegistry$get_entries(dataType = "realRatingMatrix")
names(recommendation_model)
lapply(recommendation_model, "[[", "description")
recommendation_model$IBCF_realRatingMatrix$parameters
similarity_mat <- similarity(ratingMatrix[1:4, ],
method = "cosine",
which = "users")
as.matrix(similarity_mat)
write.xlsx(ratingMatrix,paste("static_",".xlxs",sep=""))
image(as.matrix(similarity_mat), main = "User's Similarities")
similarity_mat <- similarity(ratingMatrix[1:20, ],
method = "cosine",
which = "users")
as.matrix(similarity_mat)
write.xlsx(ratingMatrix,paste("static_",".xlxs",sep=""))
image(as.matrix(similarity_mat), main = "User's Similarities")
movie_similarity <- similarity(ratingMatrix[, 1:4], method =
"cosine", which = "items")
as.matrix(movie_similarity)
image(as.matrix(movie_similarity), main = "Movies similarity")
rating_values <- as.vector(ratingMatrix@data)
unique(rating_values) # extracting unique ratings
Table_of_Ratings <- table(rating_values) # creating a count of movie ratings
Table_of_Ratings
library(ggplot2)
movie_views <- colCounts(ratingMatrix) # count views for each movie
movie_views
table_views <- data.frame(movie = names(movie_views),
views = movie_views) # create dataframe of views
table_views <- table_views[order(table_views$views,
decreasing = TRUE), ] # sort by number of views
table_views$title <- NA
for (index in 1:10325){
table_views[index,3] <- as.character(subset(movie_data,
movie_data$movieId == table_views[index,1])$title)
}
ggplot(table_views[1:6, ], aes(x = title, y = views)) +
geom_bar(stat="identity", fill = 'steelblue') +
geom_text(aes(label=views), vjust=-0.3, size=3.5) +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
ggtitle("Total Views of the Top Films")
image(ratingMatrix[1:20, 1:25], axes = FALSE, main = "Heatmap of the first 25 rows and 25 columns")
movie_ratings <- ratingMatrix[rowCounts(ratingMatrix) > 50,
colCounts(ratingMatrix) > 50]
movie_ratings
minimum_movies<- quantile(rowCounts(movie_ratings), 0.98)
minimum_users <- quantile(colCounts(movie_ratings), 0.98)
image(movie_ratings[rowCounts(movie_ratings) > minimum_movies,
colCounts(movie_ratings) > minimum_users],
main = "Heatmap of the top users and movies")
average_ratings <- rowMeans(movie_ratings)
qplot(average_ratings, fill=I("steelblue"), col=I("red")) +
ggtitle("Distribution of the average rating per user")
normalized_ratings <- normalize(movie_ratings)
sum(rowMeans(normalized_ratings) > 0.00001)
image(normalized_ratings[rowCounts(normalized_ratings) > minimum_movies,
colCounts(normalized_ratings) > minimum_users],
main = "Normalized Ratings of the Top Users")
